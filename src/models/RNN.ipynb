{"cells":[{"cell_type":"markdown","metadata":{"id":"fgHX3A5TBxFG"},"source":["# Install Libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30943,"status":"ok","timestamp":1699158752669,"user":{"displayName":"Supriya Roy","userId":"00963862192373773638"},"user_tz":-660},"id":"clPQF7m906B4","outputId":"b1ff1c13-9ae1-4efd-ae3a-0d75e7f26352"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n","Collecting sklearn\n","  Downloading sklearn-0.0.post10.tar.gz (3.6 kB)\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n","\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n","\n","\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n","\u001b[31m╰─>\u001b[0m See above for output.\n","\n","\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n","\u001b[1;36mhint\u001b[0m: See above for details.\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.3)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n","Collecting lime\n","  Downloading lime-0.2.0.1.tar.gz (275 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting shap\n","  Downloading shap-0.43.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (532 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.9/532.9 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lime) (3.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lime) (1.23.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lime) (1.11.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lime) (4.66.1)\n","Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from lime) (1.2.2)\n","Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.10/dist-packages (from lime) (0.19.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (1.5.3)\n","Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (23.2)\n","Collecting slicer==0.0.7 (from shap)\n","  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.56.4)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (3.2)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (9.4.0)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2.31.6)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2023.9.26)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (1.4.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (3.2.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.1.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (4.43.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (2.8.2)\n","Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.39.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->shap) (67.7.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2023.3.post1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n","Building wheels for collected packages: lime\n","  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=51034975a1a66790888f195087445198423153ee5de1ef96b17767767f45412e\n","  Stored in directory: /root/.cache/pip/wheels/fd/a2/af/9ac0a1a85a27f314a06b39e1f492bee1547d52549a4606ed89\n","Successfully built lime\n","Installing collected packages: slicer, shap, lime\n","Successfully installed lime-0.2.0.1 shap-0.43.0 slicer-0.0.7\n","Collecting scikeras\n","  Downloading scikeras-0.12.0-py3-none-any.whl (27 kB)\n","Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.10/dist-packages (from scikeras) (23.2)\n","Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.2.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.23.5)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.11.3)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.2.0)\n","Installing collected packages: scikeras\n","Successfully installed scikeras-0.12.0\n"]}],"source":["# !pip install tensorflow pandas numpy sklearn\n","# !pip install pandas scikit-learn\n","# !pip install lime shap\n","# !pip install scikeras"]},{"cell_type":"markdown","source":["# Import Libraries"],"metadata":{"id":"Q5NSWQAcU4nG"}},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":9096,"status":"ok","timestamp":1699158761750,"user":{"displayName":"Supriya Roy","userId":"00963862192373773638"},"user_tz":-660},"id":"vk5sMcn3KDri"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import pandas as pd\n","from datetime import timedelta\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense\n","from tensorflow.keras.metrics import AUC\n","from tensorflow.keras.metrics import Precision, TruePositives, TrueNegatives, FalsePositives, FalseNegatives, AUC\n","from sklearn.metrics import accuracy_score, recall_score, roc_auc_score\n","from keras.layers import SimpleRNN, Dense\n","import random\n","import tensorflow as tf\n","from google.colab import drive"]},{"cell_type":"markdown","source":["# Read Preprocessed Data"],"metadata":{"id":"ZZN7UxbSU617"}},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FPoCpJI4KJYO","executionInfo":{"status":"ok","timestamp":1699158787799,"user_tz":-660,"elapsed":26053,"user":{"displayName":"Supriya Roy","userId":"00963862192373773638"}},"outputId":"3614f82d-6341-4592-bfac-c822a0ccb92b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"eY1fyVSGGpq6","executionInfo":{"status":"ok","timestamp":1699159515429,"user_tz":-660,"elapsed":551,"user":{"displayName":"Supriya Roy","userId":"00963862192373773638"}}},"outputs":[],"source":["file_path_AU_preprocessed = '/content/drive/MyDrive/CKD/GitHub/data/preprocessed/AU/AU_preprocessed_df.csv'\n","file_path_JP_preprocessed = '/content/drive/MyDrive/CKD/GitHub/data/preprocessed/JP/JP_preprocessed_df.csv'"]},{"cell_type":"markdown","metadata":{"id":"Hqs0rMA7EarK"},"source":["# Train and Evaluate Models"]},{"cell_type":"markdown","metadata":{"id":"p0crvyZdhtS0"},"source":["### TUNED HYPERAMETER MODEL - AU Dataset"]},{"cell_type":"code","source":["# Read Data\n","AU_df = pd.read_csv(file_path_AU_preprocessed)\n","AU_df['COLLECTED'] = pd.to_datetime(AU_df['COLLECTED'])\n","AU_df = AU_df.reset_index(drop=True)\n","\n","# Normalize the numeric columns\n","scaler = MinMaxScaler()\n","AU_df[['AGE', 'eGFR']] = scaler.fit_transform(AU_df[['AGE', 'eGFR']])\n","\n","# Filter UIDs with sequences >= 3\n","grouped = AU_df.groupby(['ID', 'Kidney_Failure']).size().unstack(fill_value=0)\n","grouped = grouped[(grouped[1] >= 0) | (grouped[0] >= 0)] #3\n","\n","# List of columns to drop\n","cols_to_drop = ['ID', 'Kidney_Failure', 'COLLECTED']  # add other non-numeric columns if present\n","\n","X = pad_sequences(AU_df.groupby('ID').apply(lambda group: group.drop(cols_to_drop, axis=1).to_numpy()).tolist(), maxlen=50, dtype='float32', padding='post')\n","y = AU_df.groupby('ID')['Kidney_Failure'].first().to_numpy()\n","\n","# Initialise class weights\n","class_counts = np.bincount(y)\n","total_samples = np.sum(class_counts)\n","class_weights = {0: total_samples / (class_counts[0] + 1), 1: total_samples / (class_counts[1] + 1)}"],"metadata":{"id":"khc69e3FVOxr","executionInfo":{"status":"ok","timestamp":1699159526636,"user_tz":-660,"elapsed":10570,"user":{"displayName":"Supriya Roy","userId":"00963862192373773638"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":176530,"status":"ok","timestamp":1699158973446,"user":{"displayName":"Supriya Roy","userId":"00963862192373773638"},"user_tz":-660},"id":"LLfiaEbEQYGx","outputId":"f3f01f49-b08f-4203-c9a9-bef938c72edf"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n","  X, y = self._initialize(X, y)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","79/79 [==============================] - 5s 28ms/step - loss: 0.5962 - precision: 0.0646\n","Epoch 2/20\n","79/79 [==============================] - 2s 23ms/step - loss: 0.4852 - precision: 0.0000e+00\n","Epoch 3/20\n","79/79 [==============================] - 2s 21ms/step - loss: 0.3939 - precision: 0.0000e+00\n","Epoch 4/20\n","79/79 [==============================] - 1s 16ms/step - loss: 0.3191 - precision: 0.0000e+00\n","Epoch 5/20\n","79/79 [==============================] - 1s 9ms/step - loss: 0.2619 - precision: 0.0000e+00\n","Epoch 6/20\n","79/79 [==============================] - 1s 9ms/step - loss: 0.2214 - precision: 0.0000e+00\n","Epoch 7/20\n","79/79 [==============================] - 1s 9ms/step - loss: 0.1948 - precision: 0.0000e+00\n","Epoch 8/20\n","79/79 [==============================] - 1s 9ms/step - loss: 0.1783 - precision: 0.0000e+00\n","Epoch 9/20\n","79/79 [==============================] - 1s 9ms/step - loss: 0.1682 - precision: 0.0000e+00\n","Epoch 10/20\n","79/79 [==============================] - 1s 9ms/step - loss: 0.1621 - precision: 0.0000e+00\n","Epoch 11/20\n","79/79 [==============================] - 1s 9ms/step - loss: 0.1584 - precision: 0.0000e+00\n","Epoch 12/20\n","79/79 [==============================] - 1s 9ms/step - loss: 0.1560 - precision: 0.0000e+00\n","Epoch 13/20\n","79/79 [==============================] - 1s 14ms/step - loss: 0.1545 - precision: 0.0000e+00\n","Epoch 14/20\n","79/79 [==============================] - 2s 21ms/step - loss: 0.1535 - precision: 0.0000e+00\n","Epoch 15/20\n","79/79 [==============================] - 2s 26ms/step - loss: 0.1529 - precision: 0.0000e+00\n","Epoch 16/20\n","79/79 [==============================] - 2s 24ms/step - loss: 0.1525 - precision: 0.0000e+00\n","Epoch 17/20\n","79/79 [==============================] - 1s 18ms/step - loss: 0.1522 - precision: 0.0000e+00\n","Epoch 18/20\n","79/79 [==============================] - 1s 18ms/step - loss: 0.1521 - precision: 0.0000e+00\n","Epoch 19/20\n","79/79 [==============================] - 2s 21ms/step - loss: 0.1520 - precision: 0.0000e+00\n","Epoch 20/20\n","79/79 [==============================] - 2s 19ms/step - loss: 0.1519 - precision: 0.0000e+00\n","Best: 0.000000 using {'model__lr': 0.001}\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import StratifiedKFold, GridSearchCV\n","from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score, f1_score\n","from keras.models import Sequential\n","from keras.layers import SimpleRNN, Dense\n","from keras.optimizers import Adam\n","from scikeras.wrappers import KerasClassifier, KerasRegressor\n","\n","# Set random seeds\n","seed_value = 3\n","np.random.seed(seed_value)\n","\n","# Adjust this threshold as needed\n","threshold = 0.5\n","\n","# Create a dataframe to store the results\n","df_results = pd.DataFrame(columns=['TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives',\n","                                   'TPR', 'TNR', 'FPR', 'FNR',\n","                                   'Accuracy', 'Precision', 'Recall', 'f1_score', 'Specificity', 'ROC-AUC'])\n","\n","# Function to create the model, required for KerasClassifier\n","def create_model(lr=0.001):\n","    # Create model\n","    model = Sequential()\n","    model.add(SimpleRNN(units=3, input_shape=(50, 3), return_sequences=False))\n","    model.add(Dense(1, activation='sigmoid'))\n","    optimizer = Adam(learning_rate=lr)\n","    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=Precision())\n","    return model\n","\n","# Create the KerasClassifier\n","model = KerasClassifier(build_fn=create_model, epochs=20, batch_size=128, lr=0.001, verbose=1)\n","\n","# Define the grid search parameters\n","param_grid = {\n","    #'epochs': [10, 50],\n","    #'batch_size': [32, 128],\n","    'model__lr': [0.001, 0.01, 0.1] # Prefix with 'model__' to denote it's a parameter for the model-building function\n","}\n","\n","#grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n","grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='precision', n_jobs=-1, cv=3)\n","\n","grid_result = grid.fit(X, y)\n","\n","# Output the best parameters and score\n","print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":211347,"status":"ok","timestamp":1699159748414,"user":{"displayName":"Supriya Roy","userId":"00963862192373773638"},"user_tz":-660},"id":"GTJiOO5BPZ-t","outputId":"17eb9419-1e1d-4e6f-a49f-f6df6394a0dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","63/63 [==============================] - 4s 22ms/step - loss: 1.3494 - precision_7: 0.0504\n","Epoch 2/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.3355 - precision_7: 0.0552\n","Epoch 3/50\n","63/63 [==============================] - 1s 9ms/step - loss: 1.3286 - precision_7: 0.0550\n","Epoch 4/50\n","63/63 [==============================] - 1s 9ms/step - loss: 1.3165 - precision_7: 0.0598\n","Epoch 5/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.3086 - precision_7: 0.0581\n","Epoch 6/50\n","63/63 [==============================] - 1s 9ms/step - loss: 1.2934 - precision_7: 0.0683\n","Epoch 7/50\n","63/63 [==============================] - 1s 14ms/step - loss: 1.2815 - precision_7: 0.0634\n","Epoch 8/50\n","63/63 [==============================] - 1s 23ms/step - loss: 1.2688 - precision_7: 0.0680\n","Epoch 9/50\n","63/63 [==============================] - 2s 35ms/step - loss: 1.2569 - precision_7: 0.0741\n","Epoch 10/50\n","63/63 [==============================] - 1s 18ms/step - loss: 1.2504 - precision_7: 0.0748\n","Epoch 11/50\n","63/63 [==============================] - 1s 17ms/step - loss: 1.2354 - precision_7: 0.0807\n","Epoch 12/50\n","63/63 [==============================] - 1s 11ms/step - loss: 1.2337 - precision_7: 0.0846\n","Epoch 13/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.2253 - precision_7: 0.0964\n","Epoch 14/50\n","63/63 [==============================] - 1s 9ms/step - loss: 1.2118 - precision_7: 0.1029\n","Epoch 15/50\n","63/63 [==============================] - 1s 9ms/step - loss: 1.1992 - precision_7: 0.1129\n","Epoch 16/50\n","63/63 [==============================] - 1s 9ms/step - loss: 1.1839 - precision_7: 0.1251\n","Epoch 17/50\n","63/63 [==============================] - 1s 9ms/step - loss: 1.1697 - precision_7: 0.1315\n","Epoch 18/50\n","63/63 [==============================] - 1s 9ms/step - loss: 1.1621 - precision_7: 0.1277\n","Epoch 19/50\n","63/63 [==============================] - 1s 9ms/step - loss: 1.1498 - precision_7: 0.1275\n","Epoch 20/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1425 - precision_7: 0.1364\n","Epoch 21/50\n","63/63 [==============================] - 1s 9ms/step - loss: 1.1358 - precision_7: 0.1212\n","Epoch 22/50\n","63/63 [==============================] - 1s 9ms/step - loss: 1.1212 - precision_7: 0.1357\n","Epoch 23/50\n","63/63 [==============================] - 1s 9ms/step - loss: 1.1135 - precision_7: 0.1455\n","Epoch 24/50\n","63/63 [==============================] - 1s 9ms/step - loss: 1.0934 - precision_7: 0.1364\n","Epoch 25/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.0821 - precision_7: 0.1420\n","Epoch 26/50\n","63/63 [==============================] - 1s 9ms/step - loss: 1.0626 - precision_7: 0.1194\n","Epoch 27/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.0112 - precision_7: 0.1258\n","Epoch 28/50\n","63/63 [==============================] - 1s 11ms/step - loss: 0.9550 - precision_7: 0.1319\n","Epoch 29/50\n","63/63 [==============================] - 1s 15ms/step - loss: 0.9010 - precision_7: 0.1429\n","Epoch 30/50\n","63/63 [==============================] - 1s 16ms/step - loss: 0.8822 - precision_7: 0.1400\n","Epoch 31/50\n","63/63 [==============================] - 1s 16ms/step - loss: 0.8374 - precision_7: 0.1592\n","Epoch 32/50\n","63/63 [==============================] - 1s 16ms/step - loss: 0.8116 - precision_7: 0.1679\n","Epoch 33/50\n","63/63 [==============================] - 1s 15ms/step - loss: 0.8043 - precision_7: 0.1683\n","Epoch 34/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.8201 - precision_7: 0.1586\n","Epoch 35/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.7842 - precision_7: 0.2112\n","Epoch 36/50\n","63/63 [==============================] - 1s 9ms/step - loss: 0.8138 - precision_7: 0.1543\n","Epoch 37/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.7658 - precision_7: 0.2154\n","Epoch 38/50\n","63/63 [==============================] - 1s 9ms/step - loss: 0.7590 - precision_7: 0.2119\n","Epoch 39/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.7641 - precision_7: 0.1524\n","Epoch 40/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.7958 - precision_7: 0.1317\n","Epoch 41/50\n","63/63 [==============================] - 1s 9ms/step - loss: 0.7393 - precision_7: 0.2200\n","Epoch 42/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.7665 - precision_7: 0.1584\n","Epoch 43/50\n","63/63 [==============================] - 1s 9ms/step - loss: 0.7375 - precision_7: 0.1759\n","Epoch 44/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.7433 - precision_7: 0.2149\n","Epoch 45/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.7282 - precision_7: 0.2248\n","Epoch 46/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.7603 - precision_7: 0.2005\n","Epoch 47/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.7540 - precision_7: 0.1464\n","Epoch 48/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.7277 - precision_7: 0.1862\n","Epoch 49/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.7382 - precision_7: 0.1550\n","Epoch 50/50\n","63/63 [==============================] - 1s 16ms/step - loss: 0.7428 - precision_7: 0.2012\n","{0: 1.0362438220757826, 1: 28.429378531073446}\n","63/63 [==============================] - 1s 7ms/step - loss: 0.3237 - precision_7: 0.2283\n","63/63 [==============================] - 1s 7ms/step\n","0.8902136115250869 0.22826086956521738 0.8873239436619719 0.3631123919308357 0.8903192584963955 0.9002299067318431\n","Epoch 1/50\n","63/63 [==============================] - 2s 10ms/step - loss: 1.3778 - precision_8: 0.0415\n","Epoch 2/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.3612 - precision_8: 0.0490\n","Epoch 3/50\n","63/63 [==============================] - 1s 9ms/step - loss: 1.3447 - precision_8: 0.0522\n","Epoch 4/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.3337 - precision_8: 0.0532\n","Epoch 5/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.3240 - precision_8: 0.0575\n","Epoch 6/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.3080 - precision_8: 0.0616\n","Epoch 7/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.2821 - precision_8: 0.0666\n","Epoch 8/50\n","63/63 [==============================] - 1s 9ms/step - loss: 1.2346 - precision_8: 0.0812\n","Epoch 9/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.2002 - precision_8: 0.0803\n","Epoch 10/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.2416 - precision_8: 0.0753\n","Epoch 11/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.2075 - precision_8: 0.0782\n","Epoch 12/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1917 - precision_8: 0.0816\n","Epoch 13/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1779 - precision_8: 0.0837\n","Epoch 14/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1754 - precision_8: 0.0838\n","Epoch 15/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1677 - precision_8: 0.0836\n","Epoch 16/50\n","63/63 [==============================] - 1s 16ms/step - loss: 1.1554 - precision_8: 0.0812\n","Epoch 17/50\n","63/63 [==============================] - 1s 16ms/step - loss: 1.1508 - precision_8: 0.0862\n","Epoch 18/50\n","63/63 [==============================] - 1s 16ms/step - loss: 1.1470 - precision_8: 0.0876\n","Epoch 19/50\n","63/63 [==============================] - 1s 17ms/step - loss: 1.1420 - precision_8: 0.0875\n","Epoch 20/50\n","63/63 [==============================] - 1s 16ms/step - loss: 1.1364 - precision_8: 0.0903\n","Epoch 21/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1387 - precision_8: 0.0892\n","Epoch 22/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1312 - precision_8: 0.0886\n","Epoch 23/50\n","63/63 [==============================] - 1s 9ms/step - loss: 1.1347 - precision_8: 0.0885\n","Epoch 24/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1286 - precision_8: 0.0886\n","Epoch 25/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1359 - precision_8: 0.0879\n","Epoch 26/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1246 - precision_8: 0.0905\n","Epoch 27/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1204 - precision_8: 0.0918\n","Epoch 28/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1184 - precision_8: 0.0899\n","Epoch 29/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1153 - precision_8: 0.0929\n","Epoch 30/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1515 - precision_8: 0.0863\n","Epoch 31/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.2373 - precision_8: 0.0769\n","Epoch 32/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1528 - precision_8: 0.0902\n","Epoch 33/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1269 - precision_8: 0.0957\n","Epoch 34/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1215 - precision_8: 0.0929\n","Epoch 35/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1211 - precision_8: 0.0933\n","Epoch 36/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1180 - precision_8: 0.0956\n","Epoch 37/50\n","63/63 [==============================] - 1s 16ms/step - loss: 1.1158 - precision_8: 0.0945\n","Epoch 38/50\n","63/63 [==============================] - 1s 16ms/step - loss: 1.1123 - precision_8: 0.0945\n","Epoch 39/50\n","63/63 [==============================] - 1s 15ms/step - loss: 1.1112 - precision_8: 0.0962\n","Epoch 40/50\n","63/63 [==============================] - 1s 16ms/step - loss: 1.1135 - precision_8: 0.0959\n","Epoch 41/50\n","63/63 [==============================] - 1s 16ms/step - loss: 1.1142 - precision_8: 0.0956\n","Epoch 42/50\n","63/63 [==============================] - 1s 11ms/step - loss: 1.1119 - precision_8: 0.0970\n","Epoch 43/50\n","63/63 [==============================] - 1s 9ms/step - loss: 1.1114 - precision_8: 0.0970\n","Epoch 44/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1087 - precision_8: 0.0969\n","Epoch 45/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1120 - precision_8: 0.0969\n","Epoch 46/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1088 - precision_8: 0.0954\n","Epoch 47/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1037 - precision_8: 0.0978\n","Epoch 48/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1100 - precision_8: 0.1004\n","Epoch 49/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1003 - precision_8: 0.0992\n","Epoch 50/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1057 - precision_8: 0.1002\n","{0: 1.0362438220757826, 1: 28.429378531073446}\n","63/63 [==============================] - 1s 6ms/step - loss: 0.5431 - precision_8: 0.1018\n","63/63 [==============================] - 1s 7ms/step\n","0.7665176353700944 0.10179640718562874 0.7183098591549296 0.1783216783216783 0.768280123583934 0.7297834380122133\n","Epoch 1/50\n","63/63 [==============================] - 2s 10ms/step - loss: 1.4043 - precision_9: 0.0308\n","Epoch 2/50\n","63/63 [==============================] - 1s 11ms/step - loss: 1.3896 - precision_9: 0.0314\n","Epoch 3/50\n","63/63 [==============================] - 1s 11ms/step - loss: 1.3853 - precision_9: 0.0385\n","Epoch 4/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.3816 - precision_9: 0.0411\n","Epoch 5/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.3742 - precision_9: 0.0444\n","Epoch 6/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.3411 - precision_9: 0.0485\n","Epoch 7/50\n","63/63 [==============================] - 1s 11ms/step - loss: 1.3157 - precision_9: 0.0488\n","Epoch 8/50\n","63/63 [==============================] - 1s 11ms/step - loss: 1.3021 - precision_9: 0.0507\n","Epoch 9/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.2904 - precision_9: 0.0522\n","Epoch 10/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.2837 - precision_9: 0.0533\n","Epoch 11/50\n","63/63 [==============================] - 1s 11ms/step - loss: 1.2754 - precision_9: 0.0529\n","Epoch 12/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.2541 - precision_9: 0.0535\n","Epoch 13/50\n","63/63 [==============================] - 1s 11ms/step - loss: 1.2429 - precision_9: 0.0544\n","Epoch 14/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.2292 - precision_9: 0.0557\n","Epoch 15/50\n","63/63 [==============================] - 1s 17ms/step - loss: 1.2236 - precision_9: 0.0557\n","Epoch 16/50\n","63/63 [==============================] - 1s 17ms/step - loss: 1.2134 - precision_9: 0.0578\n","Epoch 17/50\n","63/63 [==============================] - 1s 18ms/step - loss: 1.2130 - precision_9: 0.0578\n","Epoch 18/50\n","63/63 [==============================] - 1s 18ms/step - loss: 1.1980 - precision_9: 0.0606\n","Epoch 19/50\n","63/63 [==============================] - 1s 14ms/step - loss: 1.1955 - precision_9: 0.0610\n","Epoch 20/50\n","63/63 [==============================] - 1s 9ms/step - loss: 1.1906 - precision_9: 0.0619\n","Epoch 21/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1789 - precision_9: 0.0629\n","Epoch 22/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1695 - precision_9: 0.0666\n","Epoch 23/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1645 - precision_9: 0.0695\n","Epoch 24/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1633 - precision_9: 0.0681\n","Epoch 25/50\n","63/63 [==============================] - 1s 9ms/step - loss: 1.1576 - precision_9: 0.0684\n","Epoch 26/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1471 - precision_9: 0.0708\n","Epoch 27/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1374 - precision_9: 0.0703\n","Epoch 28/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1360 - precision_9: 0.0701\n","Epoch 29/50\n","63/63 [==============================] - 1s 11ms/step - loss: 1.1238 - precision_9: 0.0724\n","Epoch 30/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1212 - precision_9: 0.0718\n","Epoch 31/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1130 - precision_9: 0.0741\n","Epoch 32/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1104 - precision_9: 0.0733\n","Epoch 33/50\n","63/63 [==============================] - 1s 11ms/step - loss: 1.1281 - precision_9: 0.0719\n","Epoch 34/50\n","63/63 [==============================] - 1s 11ms/step - loss: 1.1123 - precision_9: 0.0723\n","Epoch 35/50\n","63/63 [==============================] - 1s 17ms/step - loss: 1.0992 - precision_9: 0.0748\n","Epoch 36/50\n","63/63 [==============================] - 1s 17ms/step - loss: 1.0997 - precision_9: 0.0757\n","Epoch 37/50\n","63/63 [==============================] - 1s 17ms/step - loss: 1.0953 - precision_9: 0.0749\n","Epoch 38/50\n","63/63 [==============================] - 1s 18ms/step - loss: 1.0935 - precision_9: 0.0753\n","Epoch 39/50\n","63/63 [==============================] - 1s 18ms/step - loss: 1.0965 - precision_9: 0.0771\n","Epoch 40/50\n","63/63 [==============================] - 1s 11ms/step - loss: 1.0972 - precision_9: 0.0759\n","Epoch 41/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.0880 - precision_9: 0.0747\n","Epoch 42/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.0870 - precision_9: 0.0760\n","Epoch 43/50\n","63/63 [==============================] - 1s 11ms/step - loss: 1.0813 - precision_9: 0.0785\n","Epoch 44/50\n","63/63 [==============================] - 1s 11ms/step - loss: 1.0862 - precision_9: 0.0778\n","Epoch 45/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.0804 - precision_9: 0.0785\n","Epoch 46/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.0712 - precision_9: 0.0780\n","Epoch 47/50\n","63/63 [==============================] - 1s 11ms/step - loss: 1.0697 - precision_9: 0.0798\n","Epoch 48/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.0654 - precision_9: 0.0802\n","Epoch 49/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.0683 - precision_9: 0.0803\n","Epoch 50/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.0738 - precision_9: 0.0781\n","{0: 1.0362438220757826, 1: 28.429378531073446}\n","63/63 [==============================] - 1s 5ms/step - loss: 0.5493 - precision_9: 0.0804\n","63/63 [==============================] - 0s 4ms/step\n","0.6845504222553402 0.08035714285714286 0.7605633802816901 0.14535666218034993 0.6817713697219362 0.7586486996127123\n","Epoch 1/50\n","63/63 [==============================] - 3s 17ms/step - loss: 1.4319 - precision_10: 0.0342\n","Epoch 2/50\n","63/63 [==============================] - 1s 18ms/step - loss: 1.3891 - precision_10: 0.0464\n","Epoch 3/50\n","63/63 [==============================] - 1s 16ms/step - loss: 1.3730 - precision_10: 0.0464\n","Epoch 4/50\n","63/63 [==============================] - 1s 18ms/step - loss: 1.3650 - precision_10: 0.0455\n","Epoch 5/50\n","63/63 [==============================] - 1s 13ms/step - loss: 1.3581 - precision_10: 0.0484\n","Epoch 6/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.3525 - precision_10: 0.0503\n","Epoch 7/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.3484 - precision_10: 0.0486\n","Epoch 8/50\n","63/63 [==============================] - 1s 11ms/step - loss: 1.3445 - precision_10: 0.0505\n","Epoch 9/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.3412 - precision_10: 0.0490\n","Epoch 10/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.3381 - precision_10: 0.0512\n","Epoch 11/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.3346 - precision_10: 0.0500\n","Epoch 12/50\n","63/63 [==============================] - 1s 11ms/step - loss: 1.3327 - precision_10: 0.0506\n","Epoch 13/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.3286 - precision_10: 0.0500\n","Epoch 14/50\n","63/63 [==============================] - 1s 11ms/step - loss: 1.3267 - precision_10: 0.0544\n","Epoch 15/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.3226 - precision_10: 0.0543\n","Epoch 16/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.3207 - precision_10: 0.0523\n","Epoch 17/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.3169 - precision_10: 0.0555\n","Epoch 18/50\n","63/63 [==============================] - 1s 9ms/step - loss: 1.3112 - precision_10: 0.0551\n","Epoch 19/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.3061 - precision_10: 0.0566\n","Epoch 20/50\n","63/63 [==============================] - 1s 11ms/step - loss: 1.2972 - precision_10: 0.0579\n","Epoch 21/50\n","63/63 [==============================] - 1s 18ms/step - loss: 1.2765 - precision_10: 0.0639\n","Epoch 22/50\n","63/63 [==============================] - 1s 17ms/step - loss: 1.2382 - precision_10: 0.0677\n","Epoch 23/50\n","63/63 [==============================] - 1s 18ms/step - loss: 1.2269 - precision_10: 0.0644\n","Epoch 24/50\n","63/63 [==============================] - 1s 17ms/step - loss: 1.2141 - precision_10: 0.0719\n","Epoch 25/50\n","63/63 [==============================] - 1s 14ms/step - loss: 1.2146 - precision_10: 0.0747\n","Epoch 26/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.2127 - precision_10: 0.0786\n","Epoch 27/50\n","63/63 [==============================] - 1s 11ms/step - loss: 1.2221 - precision_10: 0.0779\n","Epoch 28/50\n","63/63 [==============================] - 1s 11ms/step - loss: 1.2586 - precision_10: 0.0701\n","Epoch 29/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.2907 - precision_10: 0.0680\n","Epoch 30/50\n","63/63 [==============================] - 1s 11ms/step - loss: 1.2110 - precision_10: 0.0684\n","Epoch 31/50\n","63/63 [==============================] - 1s 11ms/step - loss: 1.2096 - precision_10: 0.0663\n","Epoch 32/50\n","63/63 [==============================] - 1s 11ms/step - loss: 1.2053 - precision_10: 0.0657\n","Epoch 33/50\n","63/63 [==============================] - 1s 11ms/step - loss: 1.2030 - precision_10: 0.0672\n","Epoch 34/50\n","63/63 [==============================] - 1s 11ms/step - loss: 1.2010 - precision_10: 0.0677\n","Epoch 35/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1994 - precision_10: 0.0686\n","Epoch 36/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1976 - precision_10: 0.0699\n","Epoch 37/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1997 - precision_10: 0.0664\n","Epoch 38/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.2046 - precision_10: 0.0664\n","Epoch 39/50\n","63/63 [==============================] - 1s 11ms/step - loss: 1.1984 - precision_10: 0.0682\n","Epoch 40/50\n","63/63 [==============================] - 1s 14ms/step - loss: 1.1994 - precision_10: 0.0722\n","Epoch 41/50\n","63/63 [==============================] - 1s 16ms/step - loss: 1.2034 - precision_10: 0.0706\n","Epoch 42/50\n","63/63 [==============================] - 1s 17ms/step - loss: 1.2046 - precision_10: 0.0701\n","Epoch 43/50\n","63/63 [==============================] - 1s 18ms/step - loss: 1.2030 - precision_10: 0.0706\n","Epoch 44/50\n","63/63 [==============================] - 1s 18ms/step - loss: 1.2024 - precision_10: 0.0733\n","Epoch 45/50\n","63/63 [==============================] - 1s 14ms/step - loss: 1.2003 - precision_10: 0.0734\n","Epoch 46/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1980 - precision_10: 0.0752\n","Epoch 47/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1958 - precision_10: 0.0755\n","Epoch 48/50\n","63/63 [==============================] - 1s 11ms/step - loss: 1.1931 - precision_10: 0.0787\n","Epoch 49/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1887 - precision_10: 0.0786\n","Epoch 50/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.1876 - precision_10: 0.0792\n","{0: 1.0362438220757826, 1: 28.429378531073446}\n","63/63 [==============================] - 1s 5ms/step - loss: 0.5915 - precision_10: 0.0699\n","63/63 [==============================] - 0s 4ms/step\n","0.7208147044212618 0.06993006993006994 0.5714285714285714 0.12461059190031154 0.7261966031909418 0.7143298286890669\n","Epoch 1/50\n","63/63 [==============================] - 2s 10ms/step - loss: 1.3820 - precision_11: 0.0373\n","Epoch 2/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.3593 - precision_11: 0.0468\n","Epoch 3/50\n","63/63 [==============================] - 1s 10ms/step - loss: 1.3103 - precision_11: 0.0548\n","Epoch 4/50\n","63/63 [==============================] - 1s 16ms/step - loss: 1.1426 - precision_11: 0.0879\n","Epoch 5/50\n","63/63 [==============================] - 1s 16ms/step - loss: 1.0746 - precision_11: 0.0959\n","Epoch 6/50\n","63/63 [==============================] - 1s 16ms/step - loss: 1.0816 - precision_11: 0.1392\n","Epoch 7/50\n","63/63 [==============================] - 1s 17ms/step - loss: 1.0344 - precision_11: 0.1128\n","Epoch 8/50\n","63/63 [==============================] - 1s 17ms/step - loss: 1.0062 - precision_11: 0.1174\n","Epoch 9/50\n","63/63 [==============================] - 1s 12ms/step - loss: 1.0000 - precision_11: 0.1335\n","Epoch 10/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.9903 - precision_11: 0.1239\n","Epoch 11/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.9801 - precision_11: 0.1172\n","Epoch 12/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.9756 - precision_11: 0.1227\n","Epoch 13/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.9798 - precision_11: 0.1261\n","Epoch 14/50\n","63/63 [==============================] - 1s 11ms/step - loss: 0.9664 - precision_11: 0.1180\n","Epoch 15/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.9521 - precision_11: 0.1261\n","Epoch 16/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.9486 - precision_11: 0.1347\n","Epoch 17/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.9389 - precision_11: 0.1346\n","Epoch 18/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.9378 - precision_11: 0.1387\n","Epoch 19/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.9239 - precision_11: 0.1359\n","Epoch 20/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.9240 - precision_11: 0.1551\n","Epoch 21/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.9226 - precision_11: 0.1299\n","Epoch 22/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.9251 - precision_11: 0.1158\n","Epoch 23/50\n","63/63 [==============================] - 1s 9ms/step - loss: 0.9222 - precision_11: 0.1185\n","Epoch 24/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.9137 - precision_11: 0.1225\n","Epoch 25/50\n","63/63 [==============================] - 1s 16ms/step - loss: 0.9185 - precision_11: 0.1302\n","Epoch 26/50\n","63/63 [==============================] - 1s 16ms/step - loss: 0.9198 - precision_11: 0.1357\n","Epoch 27/50\n","63/63 [==============================] - 1s 15ms/step - loss: 0.9292 - precision_11: 0.1311\n","Epoch 28/50\n","63/63 [==============================] - 1s 16ms/step - loss: 0.9018 - precision_11: 0.1287\n","Epoch 29/50\n","63/63 [==============================] - 1s 17ms/step - loss: 0.8965 - precision_11: 0.1351\n","Epoch 30/50\n","63/63 [==============================] - 1s 12ms/step - loss: 0.8876 - precision_11: 0.1382\n","Epoch 31/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.8849 - precision_11: 0.1372\n","Epoch 32/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.8910 - precision_11: 0.1547\n","Epoch 33/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.8818 - precision_11: 0.1396\n","Epoch 34/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.8795 - precision_11: 0.1390\n","Epoch 35/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.8792 - precision_11: 0.1416\n","Epoch 36/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.8833 - precision_11: 0.1489\n","Epoch 37/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.8690 - precision_11: 0.1513\n","Epoch 38/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.8850 - precision_11: 0.1370\n","Epoch 39/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.8753 - precision_11: 0.1463\n","Epoch 40/50\n","63/63 [==============================] - 1s 9ms/step - loss: 0.8643 - precision_11: 0.1581\n","Epoch 41/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.8601 - precision_11: 0.1556\n","Epoch 42/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.8656 - precision_11: 0.1458\n","Epoch 43/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.8603 - precision_11: 0.1541\n","Epoch 44/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.8600 - precision_11: 0.1604\n","Epoch 45/50\n","63/63 [==============================] - 1s 10ms/step - loss: 0.8718 - precision_11: 0.1498\n","Epoch 46/50\n","63/63 [==============================] - 1s 14ms/step - loss: 0.8570 - precision_11: 0.1543\n","Epoch 47/50\n","63/63 [==============================] - 1s 16ms/step - loss: 0.8502 - precision_11: 0.1491\n","Epoch 48/50\n","63/63 [==============================] - 1s 16ms/step - loss: 0.8609 - precision_11: 0.1572\n","Epoch 49/50\n","63/63 [==============================] - 1s 16ms/step - loss: 0.8489 - precision_11: 0.1565\n","Epoch 50/50\n","63/63 [==============================] - 1s 16ms/step - loss: 0.8486 - precision_11: 0.1579\n","{0: 1.0362438220757826, 1: 28.429378531073446}\n","63/63 [==============================] - 1s 5ms/step - loss: 0.3894 - precision_11: 0.1590\n","63/63 [==============================] - 0s 4ms/step\n","0.8543737574552683 0.15902140672782875 0.7428571428571429 0.26196473551637284 0.8583934088568486 0.8651316757392968\n","                       Mean  Standard Deviation\n","TruePositives     52.000000            8.215838\n","TrueNegatives   1524.600000          170.488416\n","FalsePositives   417.600000          170.655501\n","FalseNegatives    18.600000            7.861298\n","TPR                0.736097            0.112856\n","TNR                0.784992            0.087853\n","FPR                0.215008            0.087853\n","FNR                0.263903            0.112856\n","Accuracy           0.783294            0.087206\n","Precision          0.127873            0.065847\n","Recall             0.736097            0.112856\n","f1_score           0.214673            0.098117\n","Specificity        0.784992            0.087853\n","ROC-AUC            0.793625            0.083762\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score, f1_score\n","\n","# Set random seeds\n","seed_value = 0\n","random.seed(seed_value)\n","np.random.seed(seed_value)\n","\n","# Adjust this threshold as needed\n","threshold = 0.5\n","\n","# Create a dataframe to store the results\n","df_results = pd.DataFrame(columns=['TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives',\n","                                   'TPR', 'TNR', 'FPR', 'FNR',\n","                                   'Accuracy', 'Precision', 'Recall', 'f1_score', 'Specificity', 'ROC-AUC'])\n","\n","# Use Stratified KFold for cross-validation\n","n_splits = 5\n","skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed_value)\n","\n","for train_idx, test_idx in skf.split(X, y):\n","    X_train, X_test = X[train_idx], X[test_idx]\n","    y_train, y_test = y[train_idx], y[test_idx]\n","\n","    # Define the model\n","    model = Sequential()\n","    model.add(SimpleRNN(units=3, input_shape=(50, 3), return_sequences=False)) #50, 4 !CHECK\n","    model.add(Dense(1, activation = 'sigmoid')) # This is just a linear combination\n","\n","    # Compile the model\n","    precision = Precision(thresholds=threshold)\n","    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[precision])\n","\n","    # Fit the model\n","    model.fit(X_train, y_train, epochs=50, batch_size=128, class_weight=class_weights)\n","    print(class_weights)\n","\n","    # Evaluate the model on the test set\n","    loss = model.evaluate(X_test, y_test)\n","\n","    # Get the predictions\n","    predictions = model.predict(X_test)\n","    predicted_labels = (predictions >= threshold).astype(int).flatten()\n","\n","    # Compute the statistics\n","    true_positives = np.sum((predicted_labels == 1) & (y_test == 1))\n","    true_negatives = np.sum((predicted_labels == 0) & (y_test == 0))\n","    false_positives = np.sum((predicted_labels == 1) & (y_test == 0))\n","    false_negatives = np.sum((predicted_labels == 0) & (y_test == 1))\n","\n","    tpr = true_positives / (true_positives + false_negatives)\n","    tnr = true_negatives / (true_negatives + false_positives)\n","    fpr = false_positives / (false_positives + true_negatives)\n","    fnr = false_negatives / (false_negatives + true_positives)\n","    accuracy = (true_positives + true_negatives) / len(y_test)\n","    precision = precision_score(y_test, predicted_labels)\n","    recall = recall_score(y_test, predicted_labels)\n","    f1 = 2 * precision * recall / (precision + recall)\n","    specificity = true_negatives / (true_negatives + false_positives)\n","    roc_auc = roc_auc_score(y_test, predictions)\n","\n","    print(accuracy, precision, recall, f1, specificity, roc_auc)\n","\n","    # Add the statistics to the dataframe\n","    df_results.loc[len(df_results)] = [true_positives, true_negatives, false_positives, false_negatives, tpr, tnr, fpr, fnr, accuracy, precision, recall, f1, specificity, roc_auc]\n","\n","# Print the average of each statistic over the 5 folds\n","mean_results = df_results.mean()\n","std_results = df_results.std()\n","\n","# Create a new DataFrame to display mean and standard deviation\n","results_summary = pd.DataFrame(index=mean_results.index)\n","results_summary['Mean'] = mean_results\n","results_summary['Standard Deviation'] = std_results\n","\n","print(results_summary)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":68177,"status":"ok","timestamp":1699160003941,"user":{"displayName":"Supriya Roy","userId":"00963862192373773638"},"user_tz":-660},"id":"DyaTs20DSf-M","outputId":"9f97e1d9-c896-4e25-a8d2-d811228df88f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","79/79 [==============================] - 6s 15ms/step - loss: 1.3597 - precision_12: 0.0519\n","Epoch 2/50\n","79/79 [==============================] - 1s 10ms/step - loss: 1.3457 - precision_12: 0.0517\n","Epoch 3/50\n","79/79 [==============================] - 1s 10ms/step - loss: 1.3314 - precision_12: 0.0554\n","Epoch 4/50\n","79/79 [==============================] - 1s 10ms/step - loss: 1.3216 - precision_12: 0.0647\n","Epoch 5/50\n","79/79 [==============================] - 1s 13ms/step - loss: 1.3005 - precision_12: 0.0636\n","Epoch 6/50\n","79/79 [==============================] - 2s 21ms/step - loss: 1.2751 - precision_12: 0.0790\n","Epoch 7/50\n","79/79 [==============================] - 1s 10ms/step - loss: 1.2467 - precision_12: 0.1010\n","Epoch 8/50\n","79/79 [==============================] - 1s 11ms/step - loss: 1.2253 - precision_12: 0.1094\n","Epoch 9/50\n","79/79 [==============================] - 1s 10ms/step - loss: 1.2170 - precision_12: 0.1135\n","Epoch 10/50\n","79/79 [==============================] - 1s 10ms/step - loss: 1.1946 - precision_12: 0.1166\n","Epoch 11/50\n","79/79 [==============================] - 1s 13ms/step - loss: 1.1841 - precision_12: 0.1124\n","Epoch 12/50\n","79/79 [==============================] - 1s 18ms/step - loss: 1.1653 - precision_12: 0.1227\n","Epoch 13/50\n","79/79 [==============================] - 2s 26ms/step - loss: 1.1468 - precision_12: 0.1167\n","Epoch 14/50\n","79/79 [==============================] - 2s 22ms/step - loss: 1.1286 - precision_12: 0.1331\n","Epoch 15/50\n","79/79 [==============================] - 1s 19ms/step - loss: 1.1081 - precision_12: 0.1344\n","Epoch 16/50\n","79/79 [==============================] - 1s 17ms/step - loss: 1.0568 - precision_12: 0.1196\n","Epoch 17/50\n","79/79 [==============================] - 1s 17ms/step - loss: 1.0427 - precision_12: 0.1529\n","Epoch 18/50\n","79/79 [==============================] - 1s 19ms/step - loss: 0.9643 - precision_12: 0.1346\n","Epoch 19/50\n","79/79 [==============================] - 1s 19ms/step - loss: 0.8871 - precision_12: 0.1468\n","Epoch 20/50\n","79/79 [==============================] - 1s 17ms/step - loss: 0.8406 - precision_12: 0.1600\n","Epoch 21/50\n","79/79 [==============================] - 2s 21ms/step - loss: 0.8340 - precision_12: 0.1549\n","Epoch 22/50\n","79/79 [==============================] - 2s 22ms/step - loss: 0.8050 - precision_12: 0.1898\n","Epoch 23/50\n","79/79 [==============================] - 2s 25ms/step - loss: 0.7754 - precision_12: 0.1891\n","Epoch 24/50\n","79/79 [==============================] - 2s 24ms/step - loss: 0.7834 - precision_12: 0.1752\n","Epoch 25/50\n","79/79 [==============================] - 2s 24ms/step - loss: 0.7999 - precision_12: 0.1597\n","Epoch 26/50\n","79/79 [==============================] - 2s 20ms/step - loss: 0.7629 - precision_12: 0.1993\n","Epoch 27/50\n","79/79 [==============================] - 2s 19ms/step - loss: 0.7560 - precision_12: 0.1521\n","Epoch 28/50\n","79/79 [==============================] - 1s 12ms/step - loss: 0.7552 - precision_12: 0.2263\n","Epoch 29/50\n","79/79 [==============================] - 1s 18ms/step - loss: 0.7463 - precision_12: 0.1904\n","Epoch 30/50\n","79/79 [==============================] - 1s 18ms/step - loss: 0.7789 - precision_12: 0.1695\n","Epoch 31/50\n","79/79 [==============================] - 1s 15ms/step - loss: 0.7370 - precision_12: 0.2296\n","Epoch 32/50\n","79/79 [==============================] - 2s 22ms/step - loss: 0.7483 - precision_12: 0.2335\n","Epoch 33/50\n","79/79 [==============================] - 2s 22ms/step - loss: 0.7342 - precision_12: 0.2099\n","Epoch 34/50\n","79/79 [==============================] - 2s 22ms/step - loss: 0.7358 - precision_12: 0.1731\n","Epoch 35/50\n","79/79 [==============================] - 1s 18ms/step - loss: 0.7519 - precision_12: 0.1864\n","Epoch 36/50\n","79/79 [==============================] - 1s 14ms/step - loss: 0.7349 - precision_12: 0.2335\n","Epoch 37/50\n","79/79 [==============================] - 1s 10ms/step - loss: 0.7214 - precision_12: 0.2155\n","Epoch 38/50\n","79/79 [==============================] - 1s 9ms/step - loss: 0.7091 - precision_12: 0.1927\n","Epoch 39/50\n","79/79 [==============================] - 1s 9ms/step - loss: 0.6979 - precision_12: 0.2166\n","Epoch 40/50\n","79/79 [==============================] - 1s 9ms/step - loss: 0.6836 - precision_12: 0.1980\n","Epoch 41/50\n","79/79 [==============================] - 1s 10ms/step - loss: 0.7539 - precision_12: 0.2126\n","Epoch 42/50\n","79/79 [==============================] - 1s 10ms/step - loss: 0.7048 - precision_12: 0.1859\n","Epoch 43/50\n","79/79 [==============================] - 1s 9ms/step - loss: 0.7214 - precision_12: 0.1585\n","Epoch 44/50\n","79/79 [==============================] - 1s 9ms/step - loss: 0.6961 - precision_12: 0.1944\n","Epoch 45/50\n","79/79 [==============================] - 1s 10ms/step - loss: 0.6799 - precision_12: 0.2136\n","Epoch 46/50\n","79/79 [==============================] - 1s 10ms/step - loss: 0.6881 - precision_12: 0.2081\n","Epoch 47/50\n","79/79 [==============================] - 1s 16ms/step - loss: 0.6615 - precision_12: 0.1998\n","Epoch 48/50\n","79/79 [==============================] - 1s 16ms/step - loss: 0.6823 - precision_12: 0.1965\n","Epoch 49/50\n","79/79 [==============================] - 1s 16ms/step - loss: 0.6791 - precision_12: 0.2021\n","Epoch 50/50\n","79/79 [==============================] - 1s 16ms/step - loss: 0.6815 - precision_12: 0.1817\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7a7cc1a7ab60>"]},"metadata":{},"execution_count":20}],"source":["# Train the final model on the full Australian dataset\n","\n","import numpy as np\n","from keras.models import Sequential\n","from keras.layers import SimpleRNN, Dense\n","from keras.metrics import Precision\n","\n","# Set random seeds for reproducibility\n","seed_value = 0\n","random.seed(seed_value)\n","np.random.seed(seed_value)\n","\n","# Adjust this threshold as needed\n","threshold = 0.5\n","\n","# Define the RNN model for the entire dataset\n","model = Sequential()\n","model.add(SimpleRNN(units=3, input_shape=(50, 3), return_sequences=False))\n","model.add(Dense(1, activation='sigmoid')) # This is a binary classification output\n","\n","# Compile the model\n","precision = Precision(thresholds=threshold)\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[precision])\n","\n","# Fit the model on the entire dataset\n","model.fit(X, y, epochs=50, batch_size=128, class_weight=class_weights)"]},{"cell_type":"markdown","metadata":{"id":"tBfvXotmYYzi"},"source":["### HELD-OUT TEST DATA - Tuned Model (Without Fine-Tuning)"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"0ZJMK7sRUjyx","executionInfo":{"status":"ok","timestamp":1699160014591,"user_tz":-660,"elapsed":1149,"user":{"displayName":"Supriya Roy","userId":"00963862192373773638"}}},"outputs":[],"source":["from pandas.tseries.offsets import DateOffset\n","import numpy as np\n","import pandas as pd\n","from sklearn.linear_model import LinearRegression\n","\n","JP_df = pd.read_csv(file_path_JP_preprocessed)\n","JP_df = JP_df.reset_index(drop=True)\n","\n","# Function to convert Time to months\n","def convert_to_months(time_str):\n","    if time_str == 'eGFR(last visit)':\n","        return 42\n","    else:\n","        return int(time_str.split('(')[-1].split('M')[0])\n","\n","# Apply the function to the 'Time' column to create a new 'Months' column\n","JP_df['Months'] = JP_df['Time'].apply(convert_to_months)\n","\n","# Assume a starting date for all IDs\n","start_date = pd.Timestamp('2020-01-01')\n","\n","# Create a 'COLLECTED' column based on the 'Months' column\n","JP_df['COLLECTED'] = JP_df.apply(lambda row: start_date + DateOffset(months=row['Months']), axis=1)\n","\n","#JP_df.drop(['Time', 'Months'], inplace = True)\n","\n","# Normalize the numeric columns\n","scaler = MinMaxScaler()\n","JP_df[['AGE', 'eGFR']] = scaler.fit_transform(JP_df[['AGE', 'eGFR']])\n","\n","# Filter UIDs with sequences >= 3\n","grouped = JP_df.groupby(['ID', 'Kidney_Failure']).size().unstack(fill_value=0)\n","grouped = grouped[(grouped[1] >= 0) | (grouped[0] >= 0)] #3\n","\n","# List of columns to drop\n","cols_to_drop = ['ID', 'Kidney_Failure', 'COLLECTED', 'Time', 'Months']  # add other non-numeric columns if present\n","\n","X = pad_sequences(JP_df.groupby('ID').apply(lambda group: group.drop(cols_to_drop, axis=1).to_numpy()).tolist(), maxlen=50, dtype='float32', padding='post')\n","y = JP_df.groupby('ID')['Kidney_Failure'].first().to_numpy()\n","\n","# Initialise class weights\n","class_counts = np.bincount(y)\n","total_samples = np.sum(class_counts)\n","class_weights = {0: total_samples / (class_counts[0] + 1), 1: total_samples / (class_counts[1] + 1)}"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":83,"status":"ok","timestamp":1699160004618,"user":{"displayName":"Supriya Roy","userId":"00963862192373773638"},"user_tz":-660},"id":"_vY0FphJUcw2","outputId":"9889b76f-b3a7-4f3b-c797-7ea1ed111ba5"},"outputs":[{"output_type":"stream","name":"stdout","text":["19/19 [==============================] - 0s 4ms/step\n","0.6700167504187605 0.45098039215686275 0.9938271604938271 0.6204238921001928 0.5494252873563218 0.7716262239250745\n","TPR: 0.9938271604938271 TNR: 0.5494252873563218 FPR: 0.45057471264367815 FNR: 0.006172839506172839 \n","Accuracy 0.6700167504187605 Precision: 0.45098039215686275 Recall: 0.9938271604938271 F1 Score: 0.6204238921001928 Specificity: 0.5494252873563218 ROC-AUC: 0.7716262239250745\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import StratifiedKFold, train_test_split\n","from sklearn.metrics import classification_report, roc_auc_score, precision_score, recall_score, accuracy_score\n","import random\n","\n","# Set random seeds\n","seed_value = 0\n","random.seed(seed_value)\n","np.random.seed(seed_value)\n","\n","# Adjust this threshold as needed\n","threshold = 0.5\n","\n","# Evaluate on the held-out test set\n","#clf = best_clf\n","\n","# Evaluate the model on the test set\n","# loss = model.evaluate(X, y)\n","\n","y_pred = model.predict(X)\n","\n","predicted_labels = (y_pred >= threshold).astype(int).flatten()\n","\n","# Compute the statistics\n","true_positives = np.sum((predicted_labels == 1) & (y == 1))\n","true_negatives = np.sum((predicted_labels == 0) & (y == 0))\n","false_positives = np.sum((predicted_labels == 1) & (y == 0))\n","false_negatives = np.sum((predicted_labels == 0) & (y == 1))\n","\n","tpr = true_positives / (true_positives + false_negatives)\n","tnr = true_negatives / (true_negatives + false_positives)\n","fpr = false_positives / (false_positives + true_negatives)\n","fnr = false_negatives / (false_negatives + true_positives)\n","accuracy = (true_positives + true_negatives) / len(y)\n","precision = precision_score(y, predicted_labels)\n","recall = recall_score(y, predicted_labels)\n","f1 = 2 * precision * recall / (precision + recall)\n","specificity = true_negatives / (true_negatives + false_positives)\n","roc_auc = roc_auc_score(y, predicted_labels)\n","#roc_auc = roc_auc_score(y, clf.predict_proba(X)[:, 1])\n","\n","print(accuracy, precision, recall, f1, specificity, roc_auc)\n","\n","print(\"TPR: {:.6g}\".format(tpr), \"TNR: {:.6g}\".format(tnr), \"FPR: {:.6g}\".format(fpr), \"FNR: {:.6g}\".format(fnr),\n","      '\\n' \"Accuracy: {:.6g}\".format(accuracy), \"Precision: {:.6g}\".format(precision), \"Recall: {:.6g}\".format(recall), \"F1 Score: {:.6g}\".format(f1_score), \"Specificity: {:.6g}\".format(specificity), \"ROC-AUC: {:.6g}\".format(roc_auc))"]},{"cell_type":"markdown","metadata":{"id":"Q--Htna_UgI7"},"source":["### HELD-OUT TEST DATA - Tuned Model (with Fine Tuning)"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"UkrGb4nzWS_b","executionInfo":{"status":"ok","timestamp":1699160006081,"user_tz":-660,"elapsed":1519,"user":{"displayName":"Supriya Roy","userId":"00963862192373773638"}}},"outputs":[],"source":["from pandas.tseries.offsets import DateOffset\n","import numpy as np\n","import pandas as pd\n","from sklearn.linear_model import LinearRegression\n","\n","JP_df = pd.read_csv(file_path_JP_preprocessed)\n","JP_df = JP_df.reset_index(drop=True)\n","\n","# Function to convert Time to months\n","def convert_to_months(time_str):\n","    if time_str == 'eGFR(last visit)':\n","        return 42\n","    else:\n","        return int(time_str.split('(')[-1].split('M')[0])\n","\n","# Apply the function to the 'Time' column to create a new 'Months' column\n","JP_df['Months'] = JP_df['Time'].apply(convert_to_months)\n","\n","# Assume a starting date for all IDs\n","start_date = pd.Timestamp('2020-01-01')\n","\n","# Create a 'COLLECTED' column based on the 'Months' column\n","JP_df['COLLECTED'] = JP_df.apply(lambda row: start_date + DateOffset(months=row['Months']), axis=1)\n","\n","#JP_df.drop(['Time', 'Months'], inplace = True)\n","\n","# Normalize the numeric columns\n","scaler = MinMaxScaler()\n","JP_df[['AGE', 'eGFR']] = scaler.fit_transform(JP_df[['AGE', 'eGFR']])\n","\n","# Filter UIDs with sequences >= 3\n","grouped = JP_df.groupby(['ID', 'Kidney_Failure']).size().unstack(fill_value=0)\n","grouped = grouped[(grouped[1] >= 0) | (grouped[0] >= 0)] #3\n","\n","# List of columns to drop\n","cols_to_drop = ['ID', 'Kidney_Failure', 'COLLECTED', 'Time', 'Months']  # add other non-numeric columns if present\n","\n","X = pad_sequences(JP_df.groupby('ID').apply(lambda group: group.drop(cols_to_drop, axis=1).to_numpy()).tolist(), maxlen=50, dtype='float32', padding='post')\n","y = JP_df.groupby('ID')['Kidney_Failure'].first().to_numpy()\n","\n","# Initialise class weights\n","class_counts = np.bincount(y)\n","total_samples = np.sum(class_counts)\n","class_weights = {0: total_samples / (class_counts[0] + 1), 1: total_samples / (class_counts[1] + 1)}\n"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1353,"status":"ok","timestamp":1699160007430,"user":{"displayName":"Supriya Roy","userId":"00963862192373773638"},"user_tz":-660},"id":"cyGKK94qR8VL","outputId":"e82a49db-4cd9-48d0-b9c8-90d07acf64d9"},"outputs":[{"output_type":"stream","name":"stdout","text":["3/3 [==============================] - 1s 11ms/step - loss: 0.7223 - precision_12: 0.4444\n","16/16 [==============================] - 0s 4ms/step\n","0.6948818897637795 0.47079037800687284 0.9927536231884058 0.6386946386946386 0.5837837837837838 0.7882687034860948\n","TPR: 0.9927536231884058 TNR: 0.5837837837837838 FPR: 0.41621621621621624 FNR: 0.007246376811594203 \n","Accuracy 0.6948818897637795 Precision: 0.47079037800687284 Recall: 0.9927536231884058 F1 Score: 0.6386946386946386 Specificity: 0.5837837837837838 ROC-AUC: 0.7882687034860948\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import StratifiedKFold, train_test_split\n","from sklearn.metrics import classification_report, roc_auc_score, precision_score, recall_score, accuracy_score\n","import random\n","from sklearn import metrics\n","import matplotlib.pyplot as plt\n","\n","# Set random seeds\n","seed_value = 0\n","random.seed(seed_value)\n","np.random.seed(seed_value)\n","\n","# Adjust this threshold as needed\n","threshold = 0.5\n","\n","# Train the model on 15% of the data\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.85, random_state=seed_value, stratify=y)\n","model.fit(X_train, y_train)\n","\n","y_pred = model.predict(X_test)\n","\n","predicted_labels = (y_pred >= threshold).astype(int).flatten()\n","\n","# Compute the statistics\n","true_positives = np.sum((predicted_labels == 1) & (y_test == 1))\n","true_negatives = np.sum((predicted_labels == 0) & (y_test == 0))\n","false_positives = np.sum((predicted_labels == 1) & (y_test == 0))\n","false_negatives = np.sum((predicted_labels == 0) & (y_test == 1))\n","\n","tpr = true_positives / (true_positives + false_negatives)\n","tnr = true_negatives / (true_negatives + false_positives)\n","fpr = false_positives / (false_positives + true_negatives)\n","fnr = false_negatives / (false_negatives + true_positives)\n","accuracy = (true_positives + true_negatives) / len(y_test)\n","precision = precision_score(y_test, predicted_labels)\n","recall = recall_score(y_test, predicted_labels)\n","f1 = 2 * precision * recall / (precision + recall)\n","specificity = true_negatives / (true_negatives + false_positives)\n","roc_auc = roc_auc_score(y_test, predicted_labels)\n","\n","print(accuracy, precision, recall, f1, specificity, roc_auc)\n","\n","print(\"TPR: {:.6g}\".format(tpr), \"TNR: {:.6g}\".format(tnr), \"FPR: {:.6g}\".format(fpr), \"FNR: {:.6g}\".format(fnr),\n","      '\\n' \"Accuracy: {:.6g}\".format(accuracy), \"Precision: {:.6g}\".format(precision), \"Recall: {:.6g}\".format(recall), \"F1 Score: {:.6g}\".format(f1_score), \"Specificity: {:.6g}\".format(specificity), \"ROC-AUC: {:.6g}\".format(roc_auc))"]}],"metadata":{"colab":{"toc_visible":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}